{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-17T16:09:57.729873Z",
     "start_time": "2019-04-17T16:09:57.534450Z"
    }
   },
   "source": [
    "<font size=20>Learning regular sets from queries and counterexamples</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-17T16:09:57.729873Z",
     "start_time": "2019-04-17T16:09:57.534450Z"
    }
   },
   "source": [
    "# Reference paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-17T16:09:57.729873Z",
     "start_time": "2019-04-17T16:09:57.534450Z"
    }
   },
   "source": [
    "## Problem statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-17T16:09:57.729873Z",
     "start_time": "2019-04-17T16:09:57.534450Z"
    }
   },
   "source": [
    "[Learning regular sets from queries and counterexamples](https://www.sciencedirect.com/science/article/pii/0890540187900526)\n",
    "\n",
    "A `Teacher` knows a regular language $\\mathcal{L}(M)$ over an alphabet $\\Sigma$ realized by a finite deterministic automaton $M$.\n",
    "\n",
    "A `Learner` tries to discover $M$. To this end, the `Learner` progressively builds an automaton $H$ based on the answers obtained from `Teacher`. The `Learner` can ask two types of questions:\n",
    "* Do $H$ and $M$ corresponds?\n",
    "  * ... where $H$ denotes the current hypothese automaton of the `Learner`.\n",
    "  * If not the teacher provides a counter example, i.e. a word $w \\in (L \\backslash \\mathcal{L}(H)) \\cup (\\mathcal{L}(H) \\backslash \\mathcal{L}(M))$\n",
    "* Does $w$ belong to $\\mathcal{L}(M)$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-17T16:09:57.729873Z",
     "start_time": "2019-04-17T16:09:57.534450Z"
    }
   },
   "source": [
    "## $L^*$ algorithm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-17T16:09:57.729873Z",
     "start_time": "2019-04-17T16:09:57.534450Z"
    }
   },
   "source": [
    "We denote by the empty word by $\\varepsilon$ (N.B. In her article, D. Angluin uses $\\lambda$ instead).\n",
    "\n",
    "The `Learner` maintains a triple $(S, E, T)$:\n",
    "* $S$ is a set of prefixes over $\\Sigma^*$, initialized to $\\{\\varepsilon\\}$;\n",
    "* $E$ is a set of suffixes over $\\Sigma^*$, initialized to $\\{\\varepsilon\\}$;\n",
    "* $T$ is the `ObservationTable`, which is in practice a 0-1 matrix $T$.\n",
    "  * Each row $i$ corresponds to a given prefix $s \\in S \\cup S.\\Sigma$, where $S.\\Sigma = {s.a, s \\in S, a \\in \\Sigma}$;\n",
    "  * Each column $j$ corresponds to a given suffix $e \\in E$;\n",
    "  * $T(i,j)$ indicates whether the word $s.e$ belongs to $L$ or not.\n",
    "\n",
    "The `Learner` updates progressively its $(S,E,T)$ triple thanks to the $L^*$ algorithm. It derives the hypothese automaton $H$ from $T$. This work is made in two steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-17T16:09:57.729873Z",
     "start_time": "2019-04-17T16:09:57.534450Z"
    }
   },
   "source": [
    "__Exploration:__\n",
    "\n",
    "To build the hypothese minimal complete DFA $H$, the `Learner` requires a _closed_ and _consistent_ `ObservationTable` (these properties are defined later). To this end, the `Learner` triggers membership queries to the `Teacher`, allowing to extend $(S, E, T)$ until these two properties hold.\n",
    "\n",
    "Once $(S,E,T)$ is closed and consistent, the `Learner` derives $H$ as follows:\n",
    "* _States:_ Each row of $S$ identifies a state of $H$. This $q$ state is when $H$ reads the prefix $s \\in S$ matching this row. $q$ is final iff $T(s, \\varepsilon)$ is true.\n",
    "* _Transitions:_ To determine egress transition of $q$, for all $a \\in \\Sigma$, the algorithm searches the row corresponding to $s+a$. This row identifies a prefix of $S$ and thus exactly one state $r$ of $H$. Thus, the $a$-transition from $q$ to $r$ is built.\n",
    "\n",
    "At the end, the `Learner` obtained a minimal finite deterministic automaton $H$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-17T16:09:57.729873Z",
     "start_time": "2019-04-17T16:09:57.534450Z"
    }
   },
   "source": [
    "__Validation:__\n",
    "\n",
    "The `Learner` proposes $H$ the `Teacher`.\n",
    "* If the `Teacher` does not return counter example, it means that $H$ is the expected automaton.\n",
    "* Otherwise, the `Teacher` returns counter-example $t$. The `Learner` insert $t$ and all its prefixes into $S$. By doing so, the `Learner` is guaranteed to only propose in the future automata returning the right result for the word $t$. Then, the `Learner` repeats the Exploration and Validation phases until $H = M$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-17T16:09:57.729873Z",
     "start_time": "2019-04-17T16:09:57.534450Z"
    }
   },
   "source": [
    "# Deterministic Finite Automaton (DFA)\n",
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T14:32:43.344894Z",
     "start_time": "2020-03-09T14:32:43.337635Z"
    }
   },
   "outputs": [],
   "source": [
    "from pybgl.automaton import Automaton, accepts, add_edge, alphabet, delta, edge, \\\n",
    "    finals, initial, is_complete, is_deterministic, is_final, is_finite, is_initial, \\\n",
    "    is_minimal, label, make_automaton, set_final, sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teacher\n",
    "\n",
    "The teacher is just a wrapper around a (minimal) deterministic automaton $M$.\n",
    "\n",
    "It exposes two main primitives:\n",
    "* _membership queries:_ \"$w \\in \\mathcal{L}(M)$?\" for some word $w \\in \\Sigma^*$.\n",
    "* _equivalence queries:_ \"$\\mathcal{L}(H) = \\mathcal{L}(M)$?\" for some hypothesis automaton $H$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T14:32:43.466270Z",
     "start_time": "2020-03-09T14:32:43.460855Z"
    }
   },
   "outputs": [],
   "source": [
    "from lstar.teacher import Teacher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Membership queries\n",
    "\n",
    "It just consists in testing whether $w$ is accepted by the automaton $M$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equivalence queries\n",
    "\n",
    "The goal here is to determine whether two automata $G_1$ and $G_2$ recognize the same language, i.e. if $\\mathcal{L}(G_1)$ = $\\mathcal{L}(G_2)$.\n",
    "* __Method 1:__ build in polynomial time the automaton recognizing $(\\mathcal{L}(G_1) \\backslash \\mathcal{L}(G_2)) \\cup (\\mathcal{L}(G_2) \\backslash \\mathcal{L}(G_1))$, and then extract any accepted word by the resulting automaton. \n",
    "* __Method 2:__ build the product automaton $G_1 \\times G_2$. If a pair $(q_1,q_2) \\in (Q_1 \\times \\{\\perp\\}) \\times (\\{\\perp\\} \\times Q_2)$ is discovered then a contradiction has been stop and we can stop the exploration.\n",
    "\n",
    "In the $L^*$ algorithm, we can simplify this test. Indeed $H$ is complete and minimal. By assuming that $M$ is also minimal, our implementation `automaton_match` only needs to check if there is bijection between the states of $M$ and $H$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T14:32:43.692182Z",
     "start_time": "2020-03-09T14:32:43.689008Z"
    }
   },
   "outputs": [],
   "source": [
    "from lstar.automaton_match import automaton_match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation table $(S,E,T)$\n",
    "\n",
    "An `ObservationTable` is a matrix in ${0,1}^{|S \\cup S.\\Sigma| \\times |E|}$ used to build the hypothesis automaton $H$.\n",
    "* We call _signature_ the row vector in ${0,1}^{|E|}$ related to a suffix $s$ in $S \\cup S.\\Sigma$. We denote it by $\\mathrm{row}(s)$.\n",
    "* Each signature of $s \\in S$ identifies exactly one state in the inferred automaton $H$.\n",
    "* Each row corresponding to a suffix in $S.\\Sigma$ helps to build complete automaton.\n",
    "\n",
    "__Definitions:__\n",
    "* An `ObservationTable` is said to be _complete_ (or _closed_) iff $\\forall t \\in S.A, \\exists s \\in S~|~row(t) = row(s)$.\n",
    "* An `ObservationTable` is said to be _consistent_ (or _separable_) iff $\\forall s \\in S, \\forall s' \\in S, \\forall a \\in \\Sigma~|~row(s) = row(s) \\implies row(s.a) = row(s'.a)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T14:32:43.961789Z",
     "start_time": "2020-03-09T14:32:43.892364Z"
    }
   },
   "outputs": [],
   "source": [
    "from lstar.observation_table import ObservationTable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the hypothesis automata $H$ from $(S,E,T)$\n",
    "\n",
    "If an `ObservationTable` is _complete_, _consistent_, then the `Learner` can derive a deterministic automaton $H$ and submit it to the `Teacher`.\n",
    "* __States:__ each state $q$ of $H$ is identified by a prefix $s \\in S$ (in particular $\\varepsilon$ identifies the initial state). Each state is identified $\\mathrm{row}(s)$. _Separability_ guarantees that these states are distinguishable\n",
    "* __Transitions:__  for each state $q$ related to a suffix $s$, and for all $a \\in \\Sigma$, the `Learner` can examine in $T$ the signature $\\mathrm{row}(s.a)$. This identifies a unique node $q'$ because $T$ is _separable_ and _closed_. This results to a $a$-transition from $q$ to $q'$.\n",
    "\n",
    "Once $H$ is built, the `Learner` can submit an equivalence query to the `Teacher` to test whether $H$ and $M$ match. If the `Teacher` returns a counter-example, the `Learner` updates its `ObservationTable` $T$. In particular, the `Learner` needs to fill $T$ and extend it until $T$ becomes complete and consistent. This forces the `Learner` to trigger several new membership queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T14:32:44.003589Z",
     "start_time": "2020-03-09T14:32:43.999558Z"
    }
   },
   "outputs": [],
   "source": [
    "from lstar.learner import Learner, make_automaton_from_observation_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T15:01:15.826747Z",
     "start_time": "2020-03-09T15:01:15.824241Z"
    }
   },
   "outputs": [],
   "source": [
    "from pybgl.graph import GraphvizStyle\n",
    "\n",
    "# Uncomment the following instruction for notebook using dark theme\n",
    "GraphvizStyle.set_fg_color(\"grey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T14:32:45.437903Z",
     "start_time": "2020-03-09T14:32:44.099682Z"
    }
   },
   "outputs": [],
   "source": [
    "from pybgl.automaton            import Automaton, is_complete, make_automaton, vertices\n",
    "from pybgl.graphviz             import dotstr_to_html\n",
    "from pybgl.html                 import html\n",
    "from pybgl.property_map         import make_func_property_map\n",
    "from lstar.automaton_match      import automaton_match\n",
    "from lstar.observation_table    import ObservationTable\n",
    "from lstar.learner              import Learner, make_automaton_from_observation_table\n",
    "from lstar.teacher              import Teacher\n",
    "\n",
    "G1 = make_automaton(\n",
    "    [\n",
    "        (0, 0, 'a'), (0, 1, 'b'),\n",
    "        (1, 2, 'a'), (1, 1, 'b'),\n",
    "        (2, 1, 'a'), (2, 1, 'b'),\n",
    "    ], 0, \n",
    "    make_func_property_map(lambda q : q in {1})\n",
    ")\n",
    "\n",
    "G2 = make_automaton(\n",
    "    [\n",
    "        (0, 0, 'a'), (0, 1, 'b'),\n",
    "    ], 0,\n",
    "    make_func_property_map(lambda q : q in {1})\n",
    ")\n",
    "\n",
    "G3 = make_automaton(\n",
    "    [\n",
    "        (0, 0, 'a'), (0, 1, 'b'),\n",
    "    ], 0,\n",
    "    make_func_property_map(lambda q : False)\n",
    ")\n",
    "\n",
    "G4 = make_automaton(\n",
    "    [\n",
    "        (0, 0, 'a'), (0, 1, 'b'),\n",
    "        (1, 1, 'b'), (1, 0, 'a')\n",
    "    ], 0,\n",
    "    make_func_property_map(lambda q : q in {1})\n",
    ")\n",
    "\n",
    "G5 = make_automaton(\n",
    "    [\n",
    "        (0, 0, 'a'), (0, 1, 'b'),\n",
    "        (1, 1, 'b'), (1, 0, 'a')\n",
    "    ], 0,\n",
    "    make_func_property_map(lambda q : False)\n",
    ")\n",
    "\n",
    "def test_learner(g :Automaton, verbose :bool = False, write_files :bool = False):\n",
    "    if not is_complete(g):\n",
    "        html(dotstr_to_html(g.to_dot()))\n",
    "        html(\"Ignored, this automaton must be finite, deterministic and complete\")\n",
    "        return\n",
    "\n",
    "    teacher = Teacher(g)\n",
    "    html(\"<b>Teacher</b>\")\n",
    "    html(dotstr_to_html(teacher.g.to_dot()))\n",
    "\n",
    "    learner = Learner(teacher)\n",
    "    h = learner.learn(verbose = verbose, write_files = write_files)\n",
    "    html(\"<b>Learner</b>\")\n",
    "    html(dotstr_to_html(h.to_dot()))\n",
    "\n",
    "    assert automaton_match(g, h) == None\n",
    "    html(\":-)\")\n",
    "\n",
    "def test_learners(gs = [G1, G2, G3, G4, G5], verbose = False):\n",
    "    for (i, g) in enumerate(gs):\n",
    "        html(\"<h3>Test G%d</h3>\" % (i + 1))\n",
    "        test_learner(g, verbose)\n",
    "        \n",
    "test_learners(verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T14:32:45.894394Z",
     "start_time": "2020-03-09T14:32:45.441533Z"
    }
   },
   "outputs": [],
   "source": [
    "G_DEMO = make_automaton(\n",
    "    [\n",
    "        (0, 0, 'a'), (0, 1, 'b'),\n",
    "        (1, 2, 'a'), (1, 1, 'b'),\n",
    "        (2, 1, 'a'), (2, 1, 'b'),\n",
    "    ], 0, make_func_property_map(lambda q: q in {1})\n",
    ")\n",
    "\n",
    "test_learner(G_DEMO, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sandbox (for slides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T14:32:45.950363Z",
     "start_time": "2020-03-09T14:32:45.897914Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pybgl.graphviz import dotstr_to_html\n",
    "from pybgl.html     import html\n",
    "\n",
    "PREFIX = \"./\"\n",
    "\n",
    "def write_automaton(g :Automaton, filename :str):\n",
    "    svg = dotstr_to_html(g.to_dot())\n",
    "    html(svg)\n",
    "    with open(filename, \"w\") as f:\n",
    "        print(\"Writting [%s]\" % filename)\n",
    "        print(svg, file=f)\n",
    "    \n",
    "write_automaton(G1, os.path.join(PREFIX, \"out_automaton.svg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T14:32:45.999208Z",
     "start_time": "2020-03-09T14:32:45.952424Z"
    }
   },
   "outputs": [],
   "source": [
    "SMALL_DFA = make_automaton(\n",
    "    [\n",
    "        (0, 0, 'a'), (0, 1, 'b'),\n",
    "        (1, 1, 'b'), (1, 0, 'a')\n",
    "    ], 0, make_func_property_map(lambda q: q in {1})\n",
    ")\n",
    "\n",
    "write_automaton(SMALL_DFA, os.path.join(PREFIX, \"small_dfa.svg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T14:32:46.058548Z",
     "start_time": "2020-03-09T14:32:46.001599Z"
    }
   },
   "outputs": [],
   "source": [
    "SMALL_TRIE = make_automaton(\n",
    "    [\n",
    "        (0, 1, 'a'), (1, 2, 'b'), (2, 3, 'a'), (2, 4, 'b'),\n",
    "        (1, 5, 'x')\n",
    "    ], 0, make_func_property_map(lambda q: q in {2,3,4,5})\n",
    ")\n",
    "\n",
    "write_automaton(SMALL_TRIE, os.path.join(PREFIX, \"small_trie.svg\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
